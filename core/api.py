import os
import math
import logging
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import client_settings as settings

logger = logging.getLogger("API")

class LabClientAPI:
    def __init__(self):
        self.base_url = settings.API_URL # åŸºç¡€URL 192.168.0.1:5000/windows-sy
        self.headers = {'Authorization': f'Bearer {settings.AUTH_TOKEN}'} # è®¤è¯å¤´
        self.machine_id = settings.INSTRUMENT_ALIAS # ä»ªå™¨åˆ«å
        self.chunk_size = settings.UPLOAD_CHUNK_SIZE # åˆ†ç‰‡å¤§å°
        
        # === ç½‘ç»œä¼˜åŒ–: Sessionå¤ç”¨ + è‡ªåŠ¨é‡è¯• ===
        self.session = requests.Session() # åˆ›å»ºä¼šè¯
        self.session.headers.update(self.headers) # ç»Ÿä¸€è®¤è¯å¤´
        
        # é‡è¯•ç­–ç•¥: é‡åˆ° 500/502/503/504 é”™è¯¯æ—¶ï¼Œè‡ªåŠ¨é‡è¯• 3 æ¬¡ï¼Œé—´éš”æŒ‡æ•°å¢é•¿
        retries = Retry(total=settings.MAX_RETRIES, 
                        backoff_factor=1, 
                        status_forcelist=[500, 502, 503, 504])
        adapter = HTTPAdapter(max_retries=retries) 
        self.session.mount('http://', adapter) 
        self.session.mount('https://', adapter)

    def _safe_request(self, method, endpoint, **kwargs):
        '''å¼‚å¸¸å®‰å…¨çš„è¯·æ±‚åŒ…è£…å™¨ï¼Œåå™¬å¼‚å¸¸å¹¶è¿”å› (Success, Response)'''
        try:
            url = f"{self.base_url}{endpoint}"
            # ä¿®å¤ï¼šè®¾ç½®é»˜è®¤è¶…æ—¶ä¸º 10ï¼Œå¦‚æœ kwargs ä¸­å·²æœ‰ timeout (å¦‚ä¸Šä¼ æ—¶çš„60s)ï¼Œåˆ™ä¿æŒä¸å˜
            kwargs.setdefault('timeout', 10)
            
            # ç›´æ¥ä¼ å…¥ kwargsï¼Œä¸å†æ‰‹åŠ¨æŒ‡å®š timeout
            resp = self.session.request(method, url, **kwargs)
            resp.raise_for_status() 
            return True, resp
        except Exception as e:
            logger.error(f"âš ï¸ APIè¯·æ±‚å¤±è´¥ [{endpoint}]: {e}")
            return False, None

    # === æ™®é€šæ¥å£ ===

    def send_audit(self, extra_data):
        '''å‘é€å®¡è®¡æ—¥å¿—'''
        extra_data['machine_id'] = self.machine_id
        success, _ = self._safe_request('POST', '/audit', json=extra_data)
        return success

    def send_operation(self, action, rel_path, extra_data):
        '''å‘é€ MKDIR/DELETE/RENAME æ“ä½œ'''
        payload = {'action': action, 'path': rel_path, 'machine_id': self.machine_id}
        payload.update(extra_data)
        success, _ = self._safe_request('POST', '/operate', json=payload)
        return success

    def check_integrity(self, rel_path, md5):
        '''æ ¡éªŒæ–‡ä»¶ä¸€è‡´æ€§'''
        payload = {"relative_path": rel_path, "md5": md5, "machine_id": self.machine_id}
        success, resp = self._safe_request('POST', '/check_integrity', json=payload)
        return resp.json() if success else None

    # === å¤§æ–‡ä»¶æ ¸å¿ƒé€»è¾‘: åˆ†ç‰‡ + æ–­ç‚¹ç»­ä¼  ===

    def upload_file_chunked(self, local_path, rel_path, file_md5, mtime, progress_callback=None):
        try:
            file_size = os.path.getsize(local_path)
            total_chunks = math.ceil(file_size / self.chunk_size)

            # 1. [æ–­ç‚¹ç»­ä¼ ] è¯¢é—®æœåŠ¡å™¨å·²æœ‰åˆ†ç‰‡
            uploaded_chunks = self._check_server_chunks(file_md5)
            
            logger.info(f"ğŸ“¤ å¼€å§‹ä¸Šä¼ : {rel_path} (å¤§å°: {file_size/1024/1024:.2f}MB, åˆ†ç‰‡: {total_chunks}, å·²è·³è¿‡: {len(uploaded_chunks)})")

            with open(local_path, 'rb') as f:
                for i in range(total_chunks):
                    # å¦‚æœåˆ†ç‰‡å·²å­˜åœ¨ï¼Œè·³è¿‡
                    if i in uploaded_chunks:
                        if progress_callback: progress_callback(i + 1, total_chunks)
                        continue

                    f.seek(i * self.chunk_size)
                    chunk_data = f.read(self.chunk_size)
                    
                    # ä¸Šä¼ å•ä¸ªåˆ†ç‰‡
                    if not self._upload_single_chunk(chunk_data, i, total_chunks, file_md5, rel_path):
                        return False, 400

                    if progress_callback: 
                        progress_callback(i + 1, total_chunks)

            # 2. [åˆå¹¶] é€šçŸ¥æœåŠ¡å™¨åˆå¹¶æ–‡ä»¶
            return self._merge_chunks(rel_path, file_md5, mtime)

        except Exception as e:
            logger.error(f"âŒ ä¸Šä¼ è¿‡ç¨‹ä¸¥é‡é”™è¯¯: {e}")
            return False, 500

    def _check_server_chunks(self, file_md5):
        '''æŸ¥è¯¢æ–­ç‚¹ä¿¡æ¯'''
        success, resp = self._safe_request('POST', '/upload/check', json={"md5": file_md5})
        if success and resp.status_code == 200:
            return set(resp.json().get("chunks", []))
        return set()

    def _upload_single_chunk(self, data, chunk_index, total_chunks, file_md5, rel_path):
        '''ä¸Šä¼ å•å—æ•°æ®'''
        files = {'file': data}
        data_payload = {
            'chunk_index': chunk_index,
            'total_chunks': total_chunks,
            'md5': file_md5,
            'relative_path': rel_path,
            'machine_id': self.machine_id
        }
        # å»¶é•¿è¶…æ—¶é˜²æ­¢å¤§å—ä¼ è¾“ä¸­æ–­
        success, _ = self._safe_request('POST', '/upload/chunk', files=files, data=data_payload, timeout=60)
        return success

    def _merge_chunks(self, rel_path, file_md5, mtime):
        '''è¯·æ±‚åˆå¹¶åˆ†ç‰‡'''
        payload = {
            'relative_path': rel_path,
            'md5': file_md5,
            'mtime': mtime,
            'machine_id': self.machine_id
        }
        success, resp = self._safe_request('POST', '/upload/merge', json=payload, timeout=30)
        if success:
            return True, resp.status_code
        return False, 500
